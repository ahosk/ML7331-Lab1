---
title: "TS_Hoskins_Reed"
author: "JR&AH"
date: '2022-07-18'
output:
  html_document: default
---


# Time Series Project

Hi, my name is Jeff Reed and my partner is Allen Hoskins.  In our project we are seeking to utilize time series tools to model the consensus earnings per share (i.e. EPS) estimates for Cummins, a manufacturer of diesel and natural gas engines.  We chose this company given the somewhat cyclical nature of their earnings over time in hopes that we could capture this and other related details using time series tools.  Before going into specific details we wanted to share some high level thoughts.
 
In regards to the stock market, one phrase that has been used is in regards to the power of a stock’s EPS trend and that “Earnings trump and trend”. This means that while getting the valuation “right” for a given stock is important, getting the earnings “right” is often more important hence the “trump” notion.  And accompanying this is the power of trends and momentum, which we believe is prevalent in the stock market and manifests itself in various ways, one of which is the earnings trajectory of a given company.
 
What we mean by earnings estimates is the median value of EPS for a given company during the next quarterly period.  These estimates are sourced from sell-side analysts whose main job is to follow, research and provide such forecasts. 
Also note, the earnings estimates typically have much more market moving implications than historical reported earnings.
The use case for modeling EPS includes valuation modeling, determining price targets as well as idea generation.
 
Our data includes 10 years of weekly EPS data for Cummins.  We analyzed the original data set and an adjusted set as we decided to remove the effects caused by COVID given it was an exogenous event.  We did this by keeping data level from early March 2020 until July 2020.  Upon analyzing the original and adjusted data we found it to evidence non-stationarity given the evidence of non-constant mean and wandering behavior in the realization as well as slowly dampening autocorrelations and a peak in the spectral density at 0.  Now I will turn it over to Allen to discuss our model building efforts.

# Initial workbook setup and Package load
```{r setup, warning=FALSE,message=FALSE,collapse=TRUE}
library(tswge)
library(tseries)
library(orcutt)
library(dplyr)
library(vars)
library(nnfor)
library(imputeTS)
library(devtools)
```


# Load in Data
Due to COVID-19, we decided to model both the full set of data as well as remove the impact of COVID by imputing mean values from tsimpute. Both data sets will be used to determine the best model.
```{r,warning=FALSE}
# load data
cmi_orig = read.csv('/Users/allen/Desktop/MSDS/Time Series/Project/TS_CMI_orig.csv', header=TRUE)
colnames(cmi_orig)[1] <- "EPS"

# adjust data to remove COVID / exogenous event
# kept data level from 3/13/20 to 7/24/20
cmi_covid = read.csv('/Users/allen/Desktop/MSDS/Time Series/Project/TS_CMI_adj.csv', header=TRUE)
colnames(cmi_covid)[1] <- "EPS"

```

# Plot Realizations
The below cells plot EPS values for both the orignal and COVID adjusted data sets.

### Original Data Set
```{r,warning=FALSE}
# plot un-adjusted data
plot.ts(cmi_orig$EPS,ylab = 'EPS')
title(main = 'Realization of Original CMI Data')
```

### Covid Data Set
```{r}
# plot adjusted data
plot.ts(cmi_covid$EPS,ylab = 'EPS')
title(main = 'Realization of COVID Adjusted CMI Data')
```

# Determining Stationarity
The following cells are used to visualize the realizations of the Original and COVID adjusted data sets. `plotts.sample.wge` is used to easily plot the realization, ACF and Spectral densities. The combination of all three of these for both data sets show that the data is not stationary and needs significant work before modeling.

### Original Data Set
```{r, warning = FALSE}
# visually analyze the data
#plot full data
plotts.sample.wge(cmi_orig$EPS)

#reset plot and adjust window
dev.off()
par(mar=c(5,4,0,2) + 0.1)

#acf with lag.max adjusted to determine cyclicality
acf(cmi_orig$EPS, lag.max = 160) 
pacf(cmi_orig$EPS, lag.max = 160) 


parzen.wge(cmi_orig$EPS, trunc = 300)
plotts.sample.wge(cmi_orig$EPS, periodogram = TRUE)
```


### Covid Data Set 
```{r,warning=FALSE}
#plot COVID Adjusted Data
plotts.sample.wge(cmi_covid$EPS)

#reset plot and adjust window
dev.off()
par(mar=c(5,4,0,2) + 0.1)
#acf with lag.max adjusted to determine cyclicity
acf(cmi_covid$EPS, lag.max = 160) 
pacf(cmi_covid$EPS, lag.max = 160)

parzen.wge(cmi_covid$EPS, trunc = 300)
plotts.sample.wge(cmi_covid$EPS, periodogram = TRUE)
```

# Begin initial modeling:

In the below chunk, we began modeling our data sets. We started by running the Dickey Fuller test to determine if we had roots on the unit circle. Both the COVID adjusted and non-COIVD adjusted data sets appear to have roots on the unit circle(p-values > 0.05). This additionally proves that our data is non stationary and should be modeled as such. After running the Dickey Fuller test, we differenced the both data sets for each suspected (1-B). After differencing the data, we plotted the ACFs and from the results determined that the data did not meet visual standards for white noise. Wen then worked on removing any seasonality from the data 

### Original Data Set
```{r,warning=FALSE}
# (1 - B) suspected 
# b/c: wandering, slowly dampening autocorrelations, tests (dickey fuller)
# dickey fuller = are there roots on the unit circle, Ho = on unit circle, Ha = not
adf.test(cmi_orig$EPS)

adf.test(cmi_covid$EPS)

# Original Data Set

# then difference the data 1 - 3 times to account for each (1 - B)
cmi_orig_1 = artrans.wge(cmi_orig$EPS, phi.tr = 1)
dev.off()
par(mar=c(5,4,0,2) + 0.1)
acf(cmi_orig_1, lag.max = 160) 
pacf(cmi_orig_1, lag.max = 160)

# covid Data Set

# then difference the data 1 - 3 times to account for each (1 - B)
cmi_covid_1 = artrans.wge(cmi_covid$EPS, phi.tr = 1)
dev.off()
par(mar=c(5,4,0,2) + 0.1)
acf(cmi_covid_1, lag.max = 160) 
pacf(cmi_covid_1, lag.max = 160)
```

# AIC Fitting:
In the below cells, we utilize twsge's `aic5.wge` function to estimate the number of phi's and theta's. We compared AIC, BIC and AICC results to determine the best model 

### Original Data Set
```{r,warning =FALSE,collapse=TRUE}
# ARMA model fitting
# find p and q
aic5.wge(cmi_orig_1, p = 0:16)
aic5.wge(cmi_orig_1, p = 0:16, type = 'bic')
aic5.wge(cmi_orig_1, p = 0:16, type = 'aicc')

```

### Covid Data Set
```{r,collapse=TRUE}
# ARMA model fitting: COVID Adjusted
# find p and q
aic5.wge(cmi_covid_1, p = 0:16)
aic5.wge(cmi_covid_1, p = 0:16, type = 'bic')
aic5.wge(cmi_covid_1, p = 0:16, type = 'aicc')

```

# Estimating: 
The below cells utilize the information obtained from `aic5.wge` and combine this with `est.arma.wge` to estimate the phi and theta values.

### Original Data Set
```{r}
# create model based on results - compare to factor table system frequency
m1_orig = est.arma.wge(cmi_orig_1, p=1)

m2_orig = est.arma.wge(cmi_orig_1, p=2)
# $phi, theta, avar, mean(x)
# avar = variance of the white noise

```
### COVID Data Set
```{r}
# create model based on results - compare to factor table system frequency
m1_covid = est.arma.wge(cmi_covid_1, p=1)

m2_covid = est.arma.wge(cmi_covid_1, p=2)
# $phi, theta, avar, mean(x)
# avar = variance of the white noise

```

# Check Residuals for "whiteness"
The below cells utilize the residuals from our estimations above to determine "whiteness" of the data. To determine "whiteness" we check visually as well as use the `ljung.wge` function to statistically test this. If the resulting p-value is less than alpha, we fail to reject the null hypothesis. Therefore the data is not considered "white."

### Original Data Set
```{r}
# whitening the residuals tests (i.e. did our built model whiten the residuals?)
# examine the residuals to see which model is better
m1_orig$res
plotts.sample.wge(m1_orig$res, arlimits = TRUE)
# check plots, check acf to see if outside limit lines
m2_orig$res
plotts.sample.wge(m2_orig$res, arlimits = TRUE)

# ljung box test, Ho = 0, low p-value means there is evidence that the residuals are NOT white noise
ljung.wge(cmi_orig_1)$pval 
ljung.wge(cmi_orig_1, K = 48)$pval
# look at multiple K's(default & 48), input p and q from est.arma.wge
# do residuals appear to be white, evidence suggests

```

### Covid Data Set
```{r}
# whitening the residuals tests (i.e. did our built model whiten the residuals?)
# examine the residuals to see which model is better
m1_covid$res
plotts.sample.wge(m1_covid$res, arlimits = TRUE)
# check plots, check acf to see if outside limit lines
m2_covid$res
plotts.sample.wge(m2_covid$res, arlimits = TRUE)

# ljung box test, Ho = 0, low p-value means there is evidence that the residuals are NOT white noise
ljung.wge(cmi_covid_1)$pval 
ljung.wge(cmi_covid_1, K = 48)$pval
# look at multiple K's(default & 48), input p and q from est.arma.wge
# do residuals appear to be white, evidence suggests

```

# Forecasting:

### Original Data Set
The below cells used to forecast long and short term models for the estimations above. 
```{r,collapse=TRUE}
# forecast and evaluate

# 1 quarter ahead forecast
fm1_st = fore.arima.wge(cmi_orig$EPS, phi = m1_orig$phi, s = 53, d = 1, n.ahead = 12, lastn = TRUE, plot = TRUE)
# 3 year ahead forecast
fm1_lt = fore.arima.wge(cmi_orig$EPS, phi = m1_orig$phi, s = 53, d = 1, n.ahead = 156, lastn = TRUE, plot = TRUE)
# 1 quarter ahead forecast
fm2_st = fore.arima.wge(cmi_orig$EPS, phi = m2_orig$phi, s = 53, d = 1, n.ahead = 12, lastn = TRUE, plot = TRUE)
# 3 year ahead forecast
fm2_lt = fore.arima.wge(cmi_orig$EPS, phi = m2_orig$phi, s = 53, d = 1, n.ahead = 156, lastn = TRUE, plot = TRUE)

```

### Covid Data Set

```{r,collapse=TRUE}
# 1 quarter ahead forecast
fm1_covid_st = fore.arima.wge(cmi_covid$EPS, phi = m1_covid$phi, s = 53, d = 1, n.ahead = 12, lastn = TRUE, plot = TRUE)
# 3 year ahead forecast
fm1_covid_lt = fore.arima.wge(cmi_covid$EPS, phi = m1_covid$phi, s = 53, d = 1, n.ahead = 156, lastn = TRUE, plot = TRUE)
# 1 quarter ahead forecast
fm2_covid_st = fore.arima.wge(cmi_covid$EPS, phi = m2_covid$phi, s = 53, d = 1, n.ahead = 12, lastn = TRUE, plot = TRUE)
# 3 year ahead forecast
fm2_covid_lt = fore.arima.wge(cmi_covid$EPS, phi = m2_covid$phi, s = 53, d = 1, n.ahead = 156, lastn = TRUE, plot = TRUE)

```


# Calculating ASE: 

### Original Data Set

The below chunk calculates the ASE for each short and long term model. From the below output, it appears that both the short and long term models are comparable  with model two short and long term models slightly outperforming model one 
```{r}
AR_ST_orig_ASE1 = mean((cmi_orig$EPS[511:522] - fm1_st$f)^2)
AR_ST_orig_ASE1
AR_LT_orig_ASE1 = mean((cmi_orig$EPS[367:522] - fm1_lt$f)^2)
AR_LT_orig_ASE1
AR_ST_orig_ASE2 = mean((cmi_orig$EPS[511:522] - fm2_st$f)^2)
AR_ST_orig_ASE2
AR_LT_orig_ASE2 = mean((cmi_orig$EPS[367:522] - fm2_lt$f)^2)
AR_LT_orig_ASE2

```

### Covid Data Set

The below chunk calculates the ASE for each short and long term model. From the below output, it appears that both the short and long term models are comparable  with model two short and long term models slightly outperforming model one 
```{r}
AR_ST_covid_ASE1 = mean((cmi_covid$EPS[511:522] - fm1_covid_st$f)^2)
AR_ST_covid_ASE1
AR_LT_covid_ASE1 = mean((cmi_covid$EPS[367:522] - fm1_covid_lt$f)^2)
AR_LT_covid_ASE1
AR_ST_covid_ASE2 = mean((cmi_covid$EPS[511:522] - fm2_covid_st$f)^2)
AR_ST_covid_ASE2
AR_LT_covid_ASE2 = mean((cmi_covid$EPS[367:522] - fm2_covid_lt$f)^2)
AR_LT_covid_ASE2
```


# Calculate Rolling Window RMSE:

#### Original Data Set
The below cell calculates a rolling window RMSE for the original data models (Long and Short term). Cell is not included as ~417 plots are created when running the cell. Output is in the following cell

Example Code:
`roll_win_m1_orig_st = roll.win.rmse.wge(cmi_orig$EPS, horizon = 12, phi = m1_orig$phi, d = 1)`

```{r,collapse=TRUE,include=FALSE}
roll_win_m1_orig_st = roll.win.rmse.wge(cmi_orig$EPS, horizon = 12, phi = m1_orig$phi,  d = 1)

roll_win_m1_orig_lt =roll.win.rmse.wge(cmi_orig$EPS, horizon = 156, phi = m1_orig$phi, d = 1)

roll_win_m2_orig_st =roll.win.rmse.wge(cmi_orig$EPS, horizon = 12, phi = m2_orig$phi, d = 1)

roll_win_m2_orig_lt = roll.win.rmse.wge(cmi_orig$EPS, horizon = 156, phi = m2_orig$phi, d = 1)
```

```{r}
roll_win_m1_orig_st$rwRMSE
roll_win_m1_orig_lt$rwRMSE
roll_win_m2_orig_st$rwRMSE
roll_win_m2_orig_lt$rwRMSE
```

### COVID Data Set
The below cell calculates a rolling window RMSE for the COVID adjusted data models (Long and Short term). Output is not included as ~417 plots are created when running the cell. Output is in the following cell


Example Code:
`roll_win_m1_covid_st = roll.win.rmse.wge(cmi_covid$EPS, horizon = 12, phi = m1_covid$phi,  d = 1)`
```{r,collapse=TRUE,include=FALSE,echo = TRUE}
roll_win_m1_covid_st = roll.win.rmse.wge(cmi_covid$EPS, horizon = 12, phi = m1_covid$phi,  d = 1)

roll_win_m1_covid_lt = roll.win.rmse.wge(cmi_covid$EPS, horizon = 156, phi = m1_covid$phi,  d = 1)

roll_win_m2_covid_st = roll.win.rmse.wge(cmi_covid$EPS, horizon = 12, phi = m2_covid$phi,  d = 1)

roll_win_m2_covid_lt =roll.win.rmse.wge(cmi_covid$EPS, horizon = 156, phi = m2_covid$phi,  d = 1)

```

```{r}
roll_win_m1_covid_st$rwRMSE
roll_win_m1_covid_lt$rwRMSE
roll_win_m2_covid_st$rwRMSE
roll_win_m2_covid_lt$rwRMSE
```

# Create Signal Plus Noise Model

### Cochrane Orcutt test to check for trend in signal noise and adjusts for correlation structure
```{r, warning=FALSE,message=FALSE,collapse=TRUE}
# Original data set
t = seq(1,522,1)
df = data.frame(x = cmi_orig$EPS, t = t)
fit = lm(x~t, data = df)
cfit = cochrane.orcutt(fit)
summary(cfit)
co.wge(cmi_orig$EPS, maxp = 16)

# COVID data set
t = seq(1,522,1)
df = data.frame(x = cmi_covid$EPS, t = t)
fit = lm(x~t, data = df)
cfit = cochrane.orcutt(fit)
summary(cfit)
co.wge(cmi_covid$EPS, maxp = 16)
```
### Fit signal plus noise model on original data set
```{r}
# slr.wge - based on the assumption that the residuals are uncorrelated 
t = 1:522
reg_orig = slr.wge(cmi_orig$EPS)
reg_orig$b0hat
reg_orig$b1hat
reg_orig$res

# assess residuals
aic5.wge(reg_orig$res, p = 0:6)
aic5.wge(reg_orig$res, p = 0:6, type = 'bic')
aic5.wge(reg_orig$res, p = 0:6, type = 'aicc')
```
### Fit signal plus noise model on COVID data set
```{r}
# slr.wge - based on the assumption that the residuals are uncorrelated 
t = 1:522
reg_covid = slr.wge(cmi_covid$EPS)
reg_covid$b0hat
reg_covid$b1hat
reg_covid$res

# assess residuals
aic5.wge(reg_covid$res, p = 0:6)
aic5.wge(reg_covid$res, p = 0:6, type = 'bic')
aic5.wge(reg_covid$res, p = 0:6, type = 'aicc')

```


### Forecast signal plus noise trend model
```{r}
# Original data set
# 1 quarter ahead forecast
fm3_st = fore.sigplusnoise.wge(cmi_orig$EPS, linear = TRUE, method = 'mle', max.p = 2, n.ahead = 12, lastn = TRUE, plot = TRUE)
# 3 year ahead forecast
fm3_lt = fore.sigplusnoise.wge(cmi_orig$EPS, linear = TRUE, method = 'mle', max.p = 2, n.ahead = 156, lastn = TRUE, plot = TRUE)

# COVID data set
# 1 quarter ahead forecast
fm3_covid_st = fore.sigplusnoise.wge(cmi_covid$EPS, linear = TRUE, method = 'mle', max.p = 2, n.ahead = 12, lastn = TRUE, plot = TRUE)
# 3 year ahead forecast
fm3_covid_lt = fore.sigplusnoise.wge(cmi_covid$EPS, linear = TRUE, method = 'mle', max.p = 2, n.ahead = 156, lastn = TRUE, plot = TRUE)
```
# Calculating ASE - SIGNAL PLUS NOISE: 

### Original Data Set

The below chunk calculates the ASE for each short and long term model. From the below output, it appears that both the short and long term models are comparable  with model two short and long term models slightly outperforming model one 
```{r}
SN_ST_orig_ASE = mean((cmi_orig$EPS[511:522] - fm3_st$f)^2)
SN_ST_orig_ASE
SN_LT_orig_ASE = mean((cmi_orig$EPS[367:522] - fm3_lt$f)^2)
SN_LT_orig_ASE
```

### Covid Data Set

The below chunk calculates the ASE for each short and long term model. From the below output, it appears that both the short and long term models are comparable  with model two short and long term models slightly outperforming model one 
```{r}
SN_ST_covid_ASE = mean((cmi_covid$EPS[511:522] - fm3_covid_st$f)^2)
SN_ST_covid_ASE
SN_LT_covid_ASE = mean((cmi_covid$EPS[367:522] - fm3_covid_lt$f)^2)
SN_LT_covid_ASE
```


# VAR MODELING

### Analyze cross correlation
```{r}
# Original data set

# FPE leads EPS by 14
ccf(cmi_orig$FPE, cmi_orig$EPS)

# No information with Sales as these variables move together
ccf(cmi_orig$Sales, cmi_orig$EPS)

# Price lags by 14
ccf(cmi_orig$Price, cmi_orig$EPS)

# COVID data set

# FPE leads EPS by 14
ccf(cmi_covid$FPE, cmi_covid$EPS)

# No information with Sales as these variables move together
ccf(cmi_covid$Sales, cmi_covid$EPS)

# Price lags by 14
ccf(cmi_covid$Price, cmi_covid$EPS)
```

### Prepare data to be modeled
```{r}
# Original data set

# combine data
X_orig=cbind(cmi_orig$EPS, cmi_orig$Sales, cmi_orig$FPE, cmi_orig$Price)

# ST train and test set
X_train_orig_ST = window(X_orig, start = 1, end = 510)
X_train_orig_LT = window(X_orig, start = 1, end = 366)
X_test_orig_ST = window(X_orig, start = 511, end = 522)
X_test_orig_LT = window(X_orig, start = 367, end = 522)

# COVID data set

# combine data
X_covid=cbind(cmi_covid$EPS, cmi_covid$Sales, cmi_covid$FPE, cmi_covid$Price)

# ST train and test set
X_train_covid_ST = window(X_covid, start = 1, end = 510)
X_train_covid_LT = window(X_covid, start = 1, end = 366)
X_test_covid_ST = window(X_covid, start = 511, end = 522)
X_test_covid_LT = window(X_covid, start = 367, end = 522)

```

### Model identification
```{r}
# Original data set 

# Short term
VARselect(X_train_orig_ST, lag.max = 20, type = "both", exogen = NULL)
# AIC selects p = 2, BIC p = 1

# Long term
VARselect(X_train_orig_LT, lag.max = 20, type = "both", exogen = NULL)
# AIC selects p = 1, BIC p = 1


# COVID data set

# Short term
VARselect(X_train_covid_ST, lag.max = 20, type = "both", exogen = NULL)
# AIC selects p = 1, BIC p = 1

# Long term
VARselect(X_train_covid_LT, lag.max = 20, type = "both", exogen = NULL)
# AIC selects p = 1, BIC p = 1
```
### Parameter estimation
```{r, warning=FALSE,message=FALSE,collapse=TRUE}
# Original data set

# Short term
VAR_orig_ST = VAR(X_train_orig_ST, p=2, type="const")
summary(VAR_orig_ST)

# Long term
VAR_orig_LT = VAR(X_train_orig_LT, p=1, type="const")
summary(VAR_orig_LT)


# COVID data set

# Short term
VAR_covid_ST = VAR(X_train_covid_ST, p=1, type="const")
summary(VAR_covid_ST)

# Long term
VAR_covid_LT = VAR(X_train_covid_LT, p=1, type="const")
summary(VAR_covid_LT)

```


### Check whiteness of residuals
```{r}
# Original data set

# Short term
ljung.wge(VAR_orig_ST$varresult$y1$residuals, p=2)

# Long term
ljung.wge(VAR_orig_LT$varresult$y1$residuals, p=1)


# COVID data set

# Short term
ljung.wge(VAR_covid_ST$varresult$y1$residuals, p=1)

# Long term
ljung.wge(VAR_covid_LT$varresult$y1$residuals, p=1)
```


### VAR Forecasting
```{r}
# Original data set

# Short term
preds_orig_ST = predict(VAR_orig_ST, n.ahead = 12)

# Long term
preds_orig_LT = predict(VAR_orig_LT, n.ahead = 156)

# COVID data set

# Short term
preds_covid_ST = predict(VAR_covid_ST, n.ahead = 12)

# Long term
preds_covid_LT = predict(VAR_covid_LT, n.ahead = 156)
```

### ASE and RMSE Calculations
```{r}
# Original Data Set

# Short term
VAR_ASE_orig_ST = mean((X_test_orig_ST[,1] - preds_orig_ST$fcst$y1[,1])^2)
VAR_ASE_orig_ST 
VAR_RMSE_orig_ST = sqrt(VAR_ASE_orig_ST)
VAR_RMSE_orig_ST

# Long term
VAR_ASE_orig_LT = mean((X_test_orig_LT[,1] - preds_orig_LT$fcst$y1[,1])^2)
VAR_ASE_orig_LT
VAR_RMSE_orig_LT = sqrt(VAR_ASE_orig_LT)
VAR_RMSE_orig_LT

# ASE - COVID Data Set

# Short term
VAR_ASE_covid_ST = mean((X_test_covid_ST[,1] - preds_covid_ST$fcst$y1[,1])^2)
VAR_ASE_covid_ST 
VAR_RMSE_covid_ST = sqrt(VAR_ASE_covid_ST)
VAR_RMSE_covid_ST

# Long term
VAR_ASE_covid_LT = mean((X_test_covid_LT[,1] - preds_covid_LT$fcst$y1[,1])^2)
VAR_ASE_covid_LT
VAR_RMSE_covid_LT = sqrt(VAR_ASE_covid_LT)
VAR_RMSE_covid_LT
```

### Plot predictions vs actuals

```{r}
#Plot

# Original Data

# Short Term
plot(seq(1,522,1), cmi_orig$EPS, type = "l",xlim = c(0,522), ylab = "EPS", main = "CMI EPS Forecast")
lines(seq(511,522,1), preds_orig_ST$fcst$y1[,1], type = "l", col = "red")

# Long Term
plot(seq(1,522,1), cmi_orig$EPS, type = "l",xlim = c(0,522), ylim= c(0,10), ylab = "EPS", main = "CMI EPS Forecast")
lines(seq(367,522,1), preds_orig_LT$fcst$y1[,1], type = "l", col = "red")

# COVID Data

# Short Term
plot(seq(1,522,1), cmi_covid$EPS, type = "l",xlim = c(0,522), ylab = "EPS", main = "CMI EPS Forecast")
lines(seq(511,522,1), preds_covid_ST$fcst$y1[,1], type = "l", col = "red")

# Long Term
plot(seq(1,522,1), cmi_covid$EPS, type = "l",xlim = c(0,522), ylim= c(0,10), ylab = "EPS", main = "CMI EPS Forecast")
lines(seq(367,522,1), preds_covid_LT$fcst$y1[,1], type = "l", col = "red")

```

# NEURAL NETWORK MODELING

### Create training and test data
```{r}
# Original data set

# ST train and test set
NN_train_orig_ST = cmi_orig[1:510,]
NN_train_orig_LT = cmi_orig[1:366,]
NN_test_orig_ST = cmi_orig[511:522,]
NN_test_orig_LT = cmi_orig[367:522,]

# COVID data set

# ST train and test set
NN_train_covid_ST = cmi_covid[1:510,]
NN_train_covid_LT = cmi_covid[1:366,]
NN_test_covid_ST = cmi_covid[511:522,]
NN_test_covid_LT = cmi_covid[367:522,]
```

### Predict explanatory variables - SHORT TERM
```{r}
# Original data set - SHORT TERM

# Predict fpe Variable
fit.mlp.orig.fpe.st = mlp(ts(NN_train_covid_ST[,"FPE"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.orig.fpe.st)
fore.mlp.orig.fpe.st = forecast(fit.mlp.orig.fpe.st, h = 12)

# Predict sales Variable
fit.mlp.orig.sales.st = mlp(ts(NN_train_covid_ST[,"Sales"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.orig.sales.st)
fore.mlp.orig.sales.st = forecast(fit.mlp.orig.sales.st, h = 12)

# Predict Price Variable
fit.mlp.orig.price.st = mlp(ts(NN_train_covid_ST[,"Price"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.orig.price.st)
fore.mlp.orig.price.st = forecast(fit.mlp.orig.price.st, h = 12)

# COVID data set - SHORT TERM

# Predict fpe Variable
fit.mlp.covid.fpe.st = mlp(ts(NN_train_covid_ST[,"FPE"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.covid.fpe.st)
fore.mlp.covid.fpe.st = forecast(fit.mlp.covid.fpe.st, h = 12)

# Predict sales Variable
fit.mlp.covid.sales.st = mlp(ts(NN_train_covid_ST[,"Sales"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.covid.sales.st)
fore.mlp.covid.sales.st = forecast(fit.mlp.covid.sales.st, h = 12)

# Predict Price Variable
fit.mlp.covid.price.st = mlp(ts(NN_train_covid_ST[,"Price"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.covid.price.st)
fore.mlp.covid.price.st = forecast(fit.mlp.covid.price.st, h = 12)

```

### Predict explanatory variables - LONG TERM
```{r}
# Original data set - LONG TERM

# Predict fpe Variable
fit.mlp.orig.fpe.lt = mlp(ts(NN_train_covid_LT[,"FPE"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.orig.fpe.lt)
fore.mlp.orig.fpe.lt = forecast(fit.mlp.orig.fpe.lt, h = 156)

# Predict sales Variable
fit.mlp.orig.sales.lt = mlp(ts(NN_train_covid_LT[,"Sales"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.orig.sales.lt)
fore.mlp.orig.sales.lt = forecast(fit.mlp.orig.sales.lt, h = 156)

# Predict Price Variable
fit.mlp.orig.price.lt = mlp(ts(NN_train_covid_LT[,"Price"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.orig.price.lt)
fore.mlp.orig.price.lt = forecast(fit.mlp.orig.price.lt, h = 156)

# COVID data set - LONG TERM

# Predict fpe Variable
fit.mlp.covid.fpe.lt = mlp(ts(NN_train_covid_LT[,"FPE"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.covid.fpe.lt)
fore.mlp.covid.fpe.lt = forecast(fit.mlp.covid.fpe.lt, h = 156)

# Predict sales Variable
fit.mlp.covid.sales.lt = mlp(ts(NN_train_covid_LT[,"Sales"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.covid.sales.lt)
fore.mlp.covid.sales.lt = forecast(fit.mlp.covid.sales.lt, h = 156)

# Predict Price Variable
fit.mlp.covid.price.lt = mlp(ts(NN_train_covid_LT[,"Price"], frequency = 1), reps = 50, difforder = NULL, comb = "median", allow.det.season = TRUE, det.type = "bin")
plot(fit.mlp.covid.price.lt)
fore.mlp.covid.price.lt = forecast(fit.mlp.covid.price.lt, h = 156)

```


### Combine training and forecasts
```{r}
# Original data set

# ST
orig_st_fore = data.frame(fpe=ts(c(NN_train_orig_ST[,"FPE"],fore.mlp.orig.fpe.st$mean)),sales=ts(c(NN_train_orig_ST[,"Sales"],fore.mlp.orig.sales.st$mean)),price=ts(c(NN_train_orig_ST[,"Price"],fore.mlp.orig.price.st$mean)))

# LT
orig_lt_fore = data.frame(fpe=ts(c(NN_train_orig_LT[,"FPE"],fore.mlp.orig.fpe.lt$mean)),sales=ts(c(NN_train_orig_LT[,"Sales"],fore.mlp.orig.sales.lt$mean)),price=ts(c(NN_train_orig_LT[,"Price"],fore.mlp.orig.price.lt$mean)))


# COVID data set

# ST
covid_st_fore = data.frame(fpe=ts(c(NN_train_covid_ST[,"FPE"],fore.mlp.covid.fpe.st$mean)),sales=ts(c(NN_train_covid_ST[,"Sales"],fore.mlp.covid.sales.st$mean)),price=ts(c(NN_train_covid_ST[,"Price"],fore.mlp.covid.price.st$mean)))

# LT
covid_lt_fore = data.frame(fpe=ts(c(NN_train_covid_LT[,"FPE"],fore.mlp.covid.fpe.lt$mean)),sales=ts(c(NN_train_covid_LT[,"Sales"],fore.mlp.covid.sales.lt$mean)),price=ts(c(NN_train_covid_LT[,"Price"],fore.mlp.covid.price.lt$mean)))

```

### Fit and Forecast EPS
```{r}
# Original data set

# ST
fit.mlp.orig.eps.st = mlp(ts(NN_train_orig_ST[,"EPS"], frequency = 1), reps = 50, comb = "median", difforder = c(1), xreg = orig_st_fore, allow.det.season = TRUE)
fit.mlp.orig.eps.st
plot(fit.mlp.orig.eps.st)

fore.mlp.orig.eps.st = forecast(fit.mlp.orig.eps.st, h = 12, xreg = orig_st_fore)
plot(fore.mlp.orig.eps.st)

# LT
fit.mlp.orig.eps.lt = mlp(ts(NN_train_orig_LT[,"EPS"], frequency = 1), reps = 50, comb = "median", difforder = c(1), xreg = orig_lt_fore, allow.det.season = TRUE)
fit.mlp.orig.eps.lt
plot(fit.mlp.orig.eps.lt)

fore.mlp.orig.eps.lt = forecast(fit.mlp.orig.eps.lt, h = 156, xreg = orig_lt_fore)
plot(fore.mlp.orig.eps.lt)

# COVID data set

# ST
fit.mlp.covid.eps.st = mlp(ts(NN_train_covid_ST[,"EPS"], frequency = 1), reps = 12, comb = "median", difforder = c(1), xreg = covid_st_fore, allow.det.season = TRUE)
fit.mlp.covid.eps.st
plot(fit.mlp.covid.eps.st)

fore.mlp.covid.eps.st = forecast(fit.mlp.covid.eps.st, h = 12, xreg = covid_st_fore)
plot(fore.mlp.covid.eps.st)

# LT
fit.mlp.covid.eps.lt = mlp(ts(NN_train_covid_LT[,"EPS"], frequency = 1), reps = 12, comb = "median", difforder = c(1), xreg = covid_lt_fore, allow.det.season = TRUE)
fit.mlp.covid.eps.lt
plot(fit.mlp.covid.eps.lt)

fore.mlp.covid.eps.lt = forecast(fit.mlp.covid.eps.lt, h = 156, xreg = covid_lt_fore)
plot(fore.mlp.covid.eps.lt)
```


### ASE and RMSE Calculations
```{r}
# Original data set

# ST
NN_ASE_orig_ST = mean((NN_test_orig_ST[,"EPS"] - fore.mlp.orig.eps.st$mean)^2)
NN_ASE_orig_ST
NN_RMSE_orig_ST = sqrt(NN_ASE_orig_ST)
NN_RMSE_orig_ST

# LL
NN_ASE_orig_LT = mean((NN_test_orig_LT[,"EPS"] - fore.mlp.orig.eps.lt$mean)^2)
NN_ASE_orig_LT
NN_RMSE_orig_LT = sqrt(NN_ASE_orig_LT)
NN_RMSE_orig_LT

# COVID data set

# ST
NN_ASE_covid_ST = mean((NN_test_covid_ST[,"EPS"] - fore.mlp.covid.eps.st$mean)^2)
NN_ASE_covid_ST
NN_RMSE_covid_ST = sqrt(NN_ASE_covid_ST)
NN_RMSE_covid_ST

# LL
NN_ASE_covid_LT = mean((NN_test_covid_LT[,"EPS"] - fore.mlp.covid.eps.lt$mean)^2)
NN_ASE_covid_LT
NN_RMSE_covid_LT = sqrt(NN_ASE_covid_LT)
NN_RMSE_covid_LT
```


### Ensemble Modeling
### Pick the best two models and average their forecasts
```{r}
# covid data set

# SHORT TERM - combine ARIMA &
ensemble.st.covid = (fm1_covid_st$f + fm2_covid_st$f) / 2

# plot
plot(seq(1,522,1), cmi_covid$EPS, type = "l",xlim = c(0,522), ylab = "EPS", main = "CMI EPS Forecast")
lines(seq(511,522,1), ensemble.st.covid, type = "l", col = "red")

# ASE
AR_ST_covid_ASE_ens = mean((cmi_covid$EPS[511:522] - ensemble.st.covid)^2)
AR_ST_covid_ASE_ens
# RMSE
RMSE.covid.ensemble.st = sqrt(AR_ST_covid_ASE_ens)


# LONG TERM - combine signal plus noise & VAR
ensemble.lt.covid = (fm3_covid_lt$f + preds_covid_LT$fcst$y1[,1]) / 2

# plot
plot(seq(1,522,1), cmi_covid$EPS, type = "l",xlim = c(0,522), ylim= c(0,10), ylab = "EPS", main = "CMI EPS Forecast")
lines(seq(367,522,1), ensemble.lt.covid, type = "l", col = "red")

# ASE
LT_covid_ASE_ens = mean((cmi_covid$EPS[367:522] - ensemble.lt.covid)^2)
# RMSE
RMSE.covid.ensemble.lt = sqrt(LT_covid_ASE_ens)

```

# FINAL RESULTS COMPARISON - ASE
```{r}
# Short Term

# COVID
AR_ST_covid_ASE1
AR_ST_covid_ASE2
SN_ST_covid_ASE
VAR_ASE_covid_ST
NN_ASE_covid_ST
AR_ST_covid_ASE_ens
```

```{r}
# LONG TERM

# COVID
AR_LT_covid_ASE1
AR_LT_covid_ASE2
SN_LT_covid_ASE
VAR_ASE_covid_LT
NN_ASE_covid_LT
LT_covid_ASE_ens
```